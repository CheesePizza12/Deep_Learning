{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mook\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [1,2,3]\n",
    "y_train = [9,18,27]\n",
    "# 초기화\n",
    "W=tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "B=tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#기준\n",
    "hypothesis = x_train * W + B\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "#방식\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 Cost 297.9499 W [0.4380022] B [1.3417897]\n",
      "step 100 Cost 1.6238694 W [7.5199146] B [3.3644412]\n",
      "step 200 Cost 1.0034528 W [7.8365593] B [2.644775]\n",
      "step 300 Cost 0.62007195 W [8.08543] B [2.0790334]\n",
      "step 400 Cost 0.3831662 W [8.281065] B [1.634308]\n",
      "step 500 Cost 0.23677377 W [8.434851] B [1.2847152]\n",
      "step 600 Cost 0.1463119 W [8.555741] B [1.0099047]\n",
      "step 700 Cost 0.090412535 W [8.650771] B [0.7938776]\n",
      "step 800 Cost 0.055869337 W [8.725474] B [0.6240608]\n",
      "step 900 Cost 0.03452391 W [8.784199] B [0.4905688]\n",
      "step 1000 Cost 0.02133374 W [8.83036] B [0.38563237]\n",
      "step 1100 Cost 0.013182838 W [8.866649] B [0.30314046]\n",
      "step 1200 Cost 0.0081461435 W [8.895174] B [0.23829547]\n",
      "step 1300 Cost 0.0050338185 W [8.917596] B [0.18732245]\n",
      "step 1400 Cost 0.0031105375 W [8.935224] B [0.14725253]\n",
      "step 1500 Cost 0.0019221585 W [8.9490795] B [0.11575429]\n",
      "step 1600 Cost 0.0011878219 W [8.959971] B [0.09099341]\n",
      "step 1700 Cost 0.0007340025 W [8.9685335] B [0.0715299]\n",
      "step 1800 Cost 0.00045359923 W [8.975265] B [0.05623017]\n",
      "step 1900 Cost 0.0002803111 W [8.980554] B [0.04420358]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2000):\n",
    "    sess.run(train)\n",
    "    if step % 100 == 0:\n",
    "        print(\"step\", step, \"Cost\", sess.run(cost), 'W',sess.run(W),'B',sess.run(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "# 초기화\n",
    "W=tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "B=tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#기준\n",
    "hypothesis = X * W + B\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "#방식\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 Cost 420.64505 W [0.64555323] B [-0.20900086]\n",
      "step 100 Cost 0.75126296 W [7.9956837] B [2.2828975]\n",
      "step 200 Cost 0.4642353 W [8.210559] B [1.7945848]\n",
      "step 300 Cost 0.2868697 W [8.379427] B [1.4107087]\n",
      "step 400 Cost 0.17726731 W [8.512174] B [1.1089451]\n",
      "step 500 Cost 0.1095409 W [8.616524] B [0.8717309]\n",
      "step 600 Cost 0.067689314 W [8.698553] B [0.6852593]\n",
      "step 700 Cost 0.04182784 W [8.763036] B [0.5386763]\n",
      "step 800 Cost 0.025846986 W [8.8137245] B [0.42344877]\n",
      "step 900 Cost 0.015971918 W [8.853571] B [0.3328694]\n",
      "step 1000 Cost 0.009869759 W [8.884893] B [0.26166576]\n",
      "step 1100 Cost 0.0060988893 W [8.909515] B [0.2056927]\n",
      "step 1200 Cost 0.0037686524 W [8.928871] B [0.16169254]\n",
      "step 1300 Cost 0.0023288748 W [8.944085] B [0.1271062]\n",
      "step 1400 Cost 0.0014390809 W [8.956046] B [0.09991708]\n",
      "step 1500 Cost 0.0008892635 W [8.965448] B [0.07854348]\n",
      "step 1600 Cost 0.00054953253 W [8.972839] B [0.06174304]\n",
      "step 1700 Cost 0.00033958463 W [8.978648] B [0.04853654]\n",
      "step 1800 Cost 0.00020985755 W [8.983215] B [0.03815503]\n",
      "step 1900 Cost 0.00012969413 W [8.986804] B [0.0299952]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2000):\n",
    "    _, c, w, b =sess.run([train,cost,W,B], feed_dict={X:[1,2,3],Y:[9,18,27]})\n",
    "    if step % 100 == 0:\n",
    "        print(\"step\", step, \"Cost\", c, 'W',w,'B',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "# 초기화\n",
    "W=tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "B=tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#기준\n",
    "hypothesis = X * W + B\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "#gradient optimizer 쪼개보기\n",
    "learning_rate =0.01\n",
    "gradient = tf.reduce_mean((W*X-Y)*X)\n",
    "descent = W-learning_rate*gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "#방식\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "#train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost 483.12784\n",
      "Cost 0.106986694\n",
      "Cost 0.022843705\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n",
      "Cost 0.022419183\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2000):\n",
    "    c,_ =sess.run([cost,update], feed_dict={X:[1,2,3],Y:[9,18,27]})\n",
    "    if step % 100 == 0:\n",
    "        print(\"Cost\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 다변수 회귀\n",
    "x1_data = [10., 12., 13.,20.,34.]\n",
    "x2_data = [15., 33., 49., 33., 12.]\n",
    "x3_data = [155., 331., 492., 333., 178.]\n",
    "y_data = [111., 323., 499., 1313., 121.]\n",
    "\n",
    "x1 =tf.placeholder(tf.float32)# shape 지정 안해봄\n",
    "x2 =tf.placeholder(tf.float32)\n",
    "x3 =tf.placeholder(tf.float32)\n",
    "y =tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name= 'weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name= 'weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name= 'weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name= 'weight3')\n",
    "\n",
    "hypothesis = x1*w1+x2*w2+x3*w3+b\n",
    "\n",
    "#기준설정\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0000000001)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 cost 169215.02 hy [192.92743 414.0407  616.724   413.95148 215.48439]\n",
      "step 100 cost 169161.44 hy [193.0417  414.2844  617.08594 414.19693 215.61624]\n",
      "step 200 cost 169107.97 hy [193.15598 414.52814 617.448   414.44244 215.74811]\n",
      "step 300 cost 169054.6 hy [193.27025 414.77182 617.81    414.68796 215.87996]\n",
      "step 400 cost 169001.4 hy [193.38445 415.0153  618.1717  414.93326 216.0117 ]\n",
      "step 500 cost 168949.11 hy [193.49686 415.25504 618.52783 415.1748  216.14143]\n",
      "step 600 cost 168896.95 hy [193.6093  415.49478 618.884   415.41635 216.27116]\n",
      "step 700 cost 168844.9 hy [193.72174 415.73453 619.2401  415.65787 216.4009 ]\n",
      "step 800 cost 168792.97 hy [193.83414 415.97424 619.5962  415.89935 216.53061]\n",
      "step 900 cost 168741.14 hy [193.94653 416.21387 619.9522  416.1408  216.6603 ]\n",
      "step 1000 cost 168689.45 hy [194.0589  416.45352 620.30817 416.3822  216.79   ]\n",
      "step 1100 cost 168637.84 hy [194.1713  416.69318 620.6641  416.62366 216.9197 ]\n",
      "step 1200 cost 168586.45 hy [194.28346 416.9324  621.0195  416.86465 217.04913]\n",
      "step 1300 cost 168535.89 hy [194.39401 417.1681  621.3696  417.1021  217.17671]\n",
      "step 1400 cost 168485.45 hy [194.50455 417.4038  621.7197  417.3396  217.30429]\n",
      "step 1500 cost 168435.16 hy [194.61508 417.63947 622.0699  417.57706 217.43187]\n",
      "step 1600 cost 168384.92 hy [194.72562 417.87518 622.42    417.8145  217.55943]\n",
      "step 1700 cost 168334.78 hy [194.83615 418.11087 622.77014 418.05197 217.68701]\n",
      "step 1800 cost 168284.78 hy [194.94669 418.3466  623.12024 418.28946 217.81459]\n",
      "step 1900 cost 168234.88 hy [195.05724 418.58228 623.4704  418.52692 217.94214]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2000):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={x1:x1_data, x2:x2_data, x3:x3_data, y:y_data})\n",
    "    if step % 100 ==0:\n",
    "        print('step', step, 'cost', cost_val, 'hy', hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2차원 배열\n",
    "# 5*4 배열\n",
    "x1_data = [[10., 12., 13.,20.],\n",
    "           [15., 33., 49., 33.],\n",
    "           [155., 331., 492.,333.],\n",
    "           [111., 323., 499.,1313.]]\n",
    "# 4*1\n",
    "y_data = [[10],[23],[44],[53]]\n",
    "\n",
    "\n",
    "x =tf.placeholder(tf.float32,shape=[None,4])\n",
    "y =tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([4,1]), name= 'weight1')\n",
    "b = tf.Variable(tf.random_normal([1]), name= 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(x,w)+b\n",
    "\n",
    "\n",
    "#기준설정\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-9)\n",
    "train = optimizer.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 cost 3068668.0 hy [[  66.22242]\n",
      " [ 164.40448]\n",
      " [1657.832  ]\n",
      " [3158.972  ]]\n",
      "step 100 cost 2410792.0 hy [[  59.272137]\n",
      " [ 148.95999 ]\n",
      " [1502.3008  ]\n",
      " [2791.29    ]]\n",
      "step 200 cost 1894830.2 hy [[  53.113205]\n",
      " [ 135.26143 ]\n",
      " [1364.3518  ]\n",
      " [2465.785   ]]\n",
      "step 300 cost 1490157.5 hy [[  47.655083]\n",
      " [ 123.10911 ]\n",
      " [1241.975   ]\n",
      " [2177.6284  ]]\n",
      "step 400 cost 1172755.9 hy [[  42.81757]\n",
      " [ 112.32625]\n",
      " [1133.389  ]\n",
      " [1922.545  ]]\n",
      "step 500 cost 923791.9 hy [[  38.52968 ]\n",
      " [ 102.756226]\n",
      " [1037.0176  ]\n",
      " [1696.7483  ]]\n",
      "step 600 cost 728496.5 hy [[  34.728535]\n",
      " [  94.260414]\n",
      " [ 951.46405 ]\n",
      " [1496.8856  ]]\n",
      "step 700 cost 575288.25 hy [[  31.358446]\n",
      " [  86.71599 ]\n",
      " [ 875.49176 ]\n",
      " [1319.9879  ]]\n",
      "step 800 cost 455084.5 hy [[  28.37011 ]\n",
      " [  80.014244]\n",
      " [ 808.0055  ]\n",
      " [1163.4259  ]]\n",
      "step 900 cost 360763.66 hy [[  25.719854]\n",
      " [  74.05887 ]\n",
      " [ 748.03577 ]\n",
      " [1024.8715  ]]\n",
      "step 1000 cost 286740.4 hy [[ 23.369022]\n",
      " [ 68.764595]\n",
      " [694.72375 ]\n",
      " [902.2627  ]]\n",
      "step 1100 cost 228634.95 hy [[ 21.28336]\n",
      " [ 64.05588]\n",
      " [647.3089 ]\n",
      " [793.77344]]\n",
      "step 1200 cost 183013.1 hy [[ 19.43256]\n",
      " [ 59.86591]\n",
      " [605.1178 ]\n",
      " [697.78766]]\n",
      "step 1300 cost 147181.31 hy [[ 17.78976]\n",
      " [ 56.13542]\n",
      " [567.55414]\n",
      " [612.8729 ]]\n",
      "step 1400 cost 119027.85 hy [[ 16.331192]\n",
      " [ 52.81202 ]\n",
      " [534.0901  ]\n",
      " [537.7621  ]]\n",
      "step 1500 cost 96896.05 hy [[ 15.035777]\n",
      " [ 49.849186]\n",
      " [504.25714 ]\n",
      " [471.3316  ]]\n",
      "step 1600 cost 79487.49 hy [[ 13.884893]\n",
      " [ 47.205887]\n",
      " [477.64206 ]\n",
      " [412.58798 ]]\n",
      "step 1700 cost 65783.41 hy [[ 12.862009]\n",
      " [ 44.84563 ]\n",
      " [453.87747 ]\n",
      " [360.65024 ]]\n",
      "step 1800 cost 54985.23 hy [[ 11.952514]\n",
      " [ 42.73621 ]\n",
      " [432.6389  ]\n",
      " [314.7392  ]]\n",
      "step 1900 cost 46466.527 hy [[ 11.143454]\n",
      " [ 40.849045]\n",
      " [413.63855 ]\n",
      " [274.1641  ]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2000):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={x:x1_data,y:y_data})\n",
    "    if step % 100 ==0:\n",
    "        print('step', step, 'cost', cost_val, 'hy', hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
