{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mook\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[0,0],[0,1],[1,0],[1,1]]\n",
    "y_data = [[0],[1],[1],[0]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None,2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "#hiden layer 3층으로, layer당 노드 10개씩\n",
    "W1 = tf.Variable(tf.random_normal([2,10]))\n",
    "B1 = tf.Variable(tf.random_normal([10]))\n",
    "layer1 = tf.sigmoid(tf.matmul(X,W1)+B1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10,10]))\n",
    "B2 = tf.Variable(tf.random_normal([10]))\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1,W2)+B2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([10,10]))\n",
    "B3 = tf.Variable(tf.random_normal([10]))\n",
    "layer3 = tf.sigmoid(tf.matmul(layer1,W2)+B3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([10,1]))\n",
    "B4 = tf.Variable(tf.random_normal([1]))\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer3,W4)+B4)\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y), dtype=tf.float32))\n",
    "\n",
    "#\n",
    "# hypothesis = tf.sigmoid(tf.matmul(X,W)+B)\n",
    "# cost = -tf.reduce_mean(tf.reduce_sum(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis)))\n",
    "\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.00001)\n",
    "# train = optimizer.minimize(cost)\n",
    "\n",
    "# # sigmoid결과를 0.5기준으로 나눠주기\n",
    "# predicted = tf.cast(hypothesis>0.5, dtype=tf.float32)\n",
    "# accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y), dtype=tf.float32))\n",
    "# #unpredicted = tf.cast(hypothesis<0.5, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 cost 0.71755433\n",
      "step 200 cost 0.67823064\n",
      "step 400 cost 0.6469387\n",
      "step 600 cost 0.59585154\n",
      "step 800 cost 0.51054764\n",
      "step 1000 cost 0.3904935\n",
      "step 1200 cost 0.27108827\n",
      "step 1400 cost 0.18674235\n",
      "step 1600 cost 0.13421284\n",
      "step 1800 cost 0.10118844\n",
      "step 2000 cost 0.07945885\n",
      "step 2200 cost 0.06446316\n",
      "step 2400 cost 0.053672183\n",
      "step 2600 cost 0.045628615\n",
      "step 2800 cost 0.03945408\n",
      "step 3000 cost 0.034596056\n",
      "step 3200 cost 0.030693518\n",
      "step 3400 cost 0.027502269\n",
      "step 3600 cost 0.02485262\n",
      "step 3800 cost 0.022623278\n",
      "step 4000 cost 0.02072571\n",
      "step 4200 cost 0.019093962\n",
      "step 4400 cost 0.017678026\n",
      "step 4600 cost 0.016439488\n",
      "step 4800 cost 0.015348149\n",
      "step 5000 cost 0.0143803125\n",
      "step 5200 cost 0.0135168545\n",
      "step 5400 cost 0.012742384\n",
      "step 5600 cost 0.012044346\n",
      "step 5800 cost 0.011412337\n",
      "step 6000 cost 0.010837762\n",
      "step 6200 cost 0.010313406\n",
      "step 6400 cost 0.009833154\n",
      "step 6600 cost 0.009391883\n",
      "step 6800 cost 0.008985197\n",
      "step 7000 cost 0.00860932\n",
      "step 7200 cost 0.0082610315\n",
      "step 7400 cost 0.007937462\n",
      "step 7600 cost 0.007636139\n",
      "step 7800 cost 0.007355\n",
      "step 8000 cost 0.00709203\n",
      "step 8200 cost 0.0068456694\n",
      "step 8400 cost 0.0066144494\n",
      "step 8600 cost 0.0063970555\n",
      "step 8800 cost 0.006192277\n",
      "step 9000 cost 0.005999133\n",
      "step 9200 cost 0.005816656\n",
      "step 9400 cost 0.005644031\n",
      "step 9600 cost 0.005480473\n",
      "step 9800 cost 0.0053253784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(10000):\n",
    "    c ,_ = sess.run([cost, train], feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 200 ==0:\n",
    "        print('step', step, 'cost', c)\n",
    "sess.run(accuracy, feed_dict={X:x_data, Y:y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
